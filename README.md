# ğŸŒŠ ARGO FloatChat - AI-Powered Ocean Data Discovery Platform

A comprehensive AI-powered system for querying, analyzing, and visualizing ARGO oceanographic data using natural language processing and advanced data science techniques.


## ğŸ¯ Project Overview

ARGO FloatChat is an end-to-end platform that democratizes access to oceanographic data through AI. It combines data extraction, processing, storage, and intelligent querying capabilities to make ARGO float data accessible to researchers, students, and ocean enthusiasts worldwide.

### ğŸŒŸ Key Features

- **ğŸ¤– Natural Language Queries**: Ask questions like "Show me temperature profiles in the Indian Ocean"
- **ğŸ§  AI-Powered Analysis**: RAG (Retrieval-Augmented Generation) pipeline with multiple LLM support
- **ğŸ—ºï¸ Interactive Visualizations**: Dynamic maps, depth profiles, and time series plots
- **ğŸ“Š Multi-Modal Data Access**: Both SQL queries and semantic vector search
- **âš¡ Real-time Processing**: Fast responses using Groq API with Llama 3.1
- **ğŸŒ Geographic Intelligence**: Smart region detection and ocean-specific filtering
- **ğŸ“ˆ Advanced Analytics**: Trend analysis, statistical summaries, and data insights

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARGO FloatChat Platform                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend (Streamlit)  â”‚  Backend (FastAPI)  â”‚  Data Pipeline   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ FloatChat UI    â”‚â—„â”€â”€â”¼â”€â”€â”¤ Query Processor â”‚â”‚  â”‚ Data        â”‚ â”‚
â”‚  â”‚ Interactive     â”‚   â”‚  â”‚ RAG Pipeline    â”‚â”‚  â”‚ Extraction  â”‚ â”‚
â”‚  â”‚ Visualizations  â”‚   â”‚  â”‚ LLM Integration â”‚â”‚  â”‚ & Cleaning  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                        â”‚  â”‚ Database Layer  â”‚â”‚  â”‚ Vector DB   â”‚ â”‚
â”‚                        â”‚  â”‚ PostgreSQL      â”‚â”‚  â”‚ ChromaDB    â”‚ â”‚
â”‚                        â”‚  â”‚ Structured      â”‚â”‚  â”‚ Semantic    â”‚ â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

### ğŸ¨ Frontend (`/frontend`)
**Streamlit-based interactive web application**

- **`floatchat_app.py`**: Main Streamlit application with chat interface
- **`backend_adapter.py`**: API client for backend communication
- **`frontend_config.py`**: Configuration and constants
- **`requirements.txt`**: Frontend dependencies (Streamlit, Plotly, Leaflet.js etc.)

**Features:**
- Interactive chat interface with natural language queries
- Real-time visualizations (maps, profiles, time series)
- Export capabilities (CSV, JSON, NetCDF, PNG)
- Responsive design with modern UI/UX

### âš™ï¸ Backend (`/backend`)
**FastAPI-based REST API with AI capabilities**

- **`app/main.py`**: FastAPI application entry point
- **`app/api/routes/`**: API endpoints (query, data, health)
- **`app/core/`**: Database and LLM client management
- **`app/services/`**: Business logic (RAG pipeline, query classification)
- **`app/models/`**: Pydantic data models
- **`scripts/`**: Setup and database management scripts

**Key Components:**
- **Query Classification**: Determines SQL vs semantic search
- **RAG Pipeline**: Retrieval-Augmented Generation for intelligent responses
- **Multi-LLM Support**: Groq, Hugging Face, and other providers
- **Vector Database**: ChromaDB for semantic search, FAISS for fallback
- **PostgreSQL**: Structured data storage

### ğŸ§¹ Data Cleaning (`/data_cleaning`)
**NetCDF processing and database preparation**

- **`src/argo_data_processor.py`**: NetCDF file processing
- **`src/batch_processor.py`**: Batch processing utilities
- **`src/vector_db_manager.py`**: Vector database operations
- **`sql/database_schema.sql`**: PostgreSQL schema
- **`deliverables/`**: Export and delivery scripts

**Data Processing Pipeline:**
1. **NetCDF Processing**: Extract oceanographic profiles from ARGO files
2. **Quality Control**: Filter data based on quality flags
3. **Database Storage**: Store in PostgreSQL with optimized schema
4. **Vector Embeddings**: Create semantic search capabilities
5. **Metadata Summaries**: Generate searchable content

### ğŸ“¥ Data Extraction (`/data_extraction`)
**Automated ARGO data download and verification**

- **`efficient_downloader.py`**: Async download of NetCDF files
- **`retry_failed_downloads.py`**: Retry mechanism for failed downloads
- **`verify_downloads.py`**: Integrity checking and validation

**Download Features:**
- **Asynchronous Downloads**: Fast parallel processing
- **Retry Logic**: Automatic retry for failed downloads
- **Integrity Checking**: Verify file completeness
- **Progress Tracking**: Real-time download monitoring

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** (recommended 3.11+)
- **PostgreSQL 12+**
- **8GB+ RAM** (for embedding models)
- **10GB+ disk space** (for data storage)

### ğŸŒ Deployment Options

**For Production Deployment:**
- ğŸ“– [Complete Deployment Guide](DEPLOYMENT.md) - Deploy to Render (Backend) + Vercel (Frontend)
- âœ… [Deployment Checklist](DEPLOYMENT_CHECKLIST.md) - Step-by-step deployment verification

**For Local Development:**

### 1. Clone and Setup

```bash
git clone <repository-url>
cd argo_floatchat
```

### 2. Backend Setup

```bash
cd backend
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your database credentials

# Run complete setup
python scripts/complete_setup.py

# Start backend server
python run.py
```

### 3. Frontend Setup

```bash
cd frontend
pip install -r requirements.txt

# Start Streamlit app
streamlit run floatchat_app.py
```

### 4. Data Processing 

```bash
cd data_cleaning
pip install -r requirements.txt

# Process NetCDF files
python src/batch_processor.py

# Setup vector database
python src/vector_db_manager.py
```

## ğŸ“Š Data Coverage

Our system includes comprehensive ARGO data:

- **ğŸŒŠ 122,000+ ARGO profiles** from Indian Ocean region
- **ğŸš¢ 1,800+ ARGO floats** with trajectory data
- **ğŸŒ¡ï¸ Core Parameters**: Temperature, Salinity, Pressure, Depth
- **ğŸ§ª BGC Parameters**: Dissolved Oxygen, pH, Nitrate, Chlorophyll-a
- **ğŸ—ºï¸ Geographic Focus**: Indian Ocean, Arabian Sea, Bay of Bengal
- **ğŸ“… Temporal Coverage**: 2019-2025 (extensible)

## ğŸ”§ Configuration

### Environment Variables

```bash
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=argo_database
DB_USER=your_username
DB_PASSWORD=your_password

# AI/LLM Configuration
GROQ_API_KEY=your_groq_api_key
OPENAI_API_KEY=your_openai_api_key  # Optional

# Application Settings
DEBUG=true
HOST=127.0.0.1
PORT=8000
```

### Database Setup

The system uses two complementary databases:

1. **PostgreSQL** (Structured Data):
   - `argo_floats`: Float metadata and status
   - `argo_profiles`: Profile measurements with arrays for oceanographic parameters

2. **ChromaDB** (Semantic Search):
   - Metadata summaries for semantic search
   - Embedding-based similarity matching

## ğŸ¯ Usage Examples

### Natural Language Queries

```bash
# Data Retrieval
"Show me temperature profiles in the Arabian Sea from 2023"
"Find ARGO floats near coordinates 20Â°N, 70Â°E"
"Get salinity data for float 7900617"

# Analytical Queries
"Compare BGC parameters in the Arabian Sea vs Bay of Bengal"
"What are the temperature trends in the Indian Ocean?"
"Summarize seasonal variations in chlorophyll levels"

# Exploratory Queries
"What can you tell me about ocean warming patterns?"
"Describe the characteristics of ARGO float data"
"How does salinity vary with depth in the Southern Ocean?"
```

### API Usage

```bash
# Natural language query
curl -X POST 'http://localhost:8000/api/v1/query' \
  -H 'Content-Type: application/json' \
  -d '{
    "query": "Show me temperature profiles in the Arabian Sea from 2023",
    "max_results": 10
  }'

# Direct data search
curl -X POST 'http://localhost:8000/api/v1/data/search' \
  -H 'Content-Type: application/json' \
  -d '{
    "start_date": "2023-01-01",
    "end_date": "2023-12-31",
    "min_latitude": 10,
    "max_latitude": 25,
    "parameters": ["temperature", "salinity"]
  }'
```

## ğŸ” Query Processing Flow

The system intelligently routes queries through multiple pathways:

1. **Query Classification**: Determines the best approach (SQL vs semantic)
2. **SQL Retrieval**: For specific data requests with precise filtering
3. **Vector Retrieval**: For conceptual questions and pattern analysis
4. **Hybrid Retrieval**: Combines both approaches for complex analytical queries
5. **Response Generation**: Uses RAG pipeline for intelligent, contextual responses

## ğŸ› ï¸ Development

### Project Structure

```
argo_floatchat/
â”œâ”€â”€ frontend/                 # Streamlit web application
â”‚   â”œâ”€â”€ floatchat_app.py     # Main UI application
â”‚   â”œâ”€â”€ backend_adapter.py # API client
â”‚   â””â”€â”€ requirements.txt      # Frontend dependencies
â”œâ”€â”€ backend/                  # FastAPI REST API
â”‚   â”œâ”€â”€ app/                  # Application code
â”‚   â”‚   â”œâ”€â”€ api/routes/      # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/           # Database & LLM clients
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â””â”€â”€ models/         # Data models
â”‚   â”œâ”€â”€ scripts/            # Setup scripts
â”‚   â””â”€â”€ requirements.txt    # Backend dependencies
â”œâ”€â”€ data_cleaning/          # Data processing pipeline
â”‚   â”œâ”€â”€ src/               # Processing modules
â”‚   â”œâ”€â”€ sql/               # Database schema
â”‚   â””â”€â”€ deliverables/      # Export utilities
â”œâ”€â”€ data_extraction/       # Data download system
â”‚   â”œâ”€â”€ efficient_downloader.py
â”‚   â”œâ”€â”€ retry_failed_downloads.py
â”‚   â””â”€â”€ verify_downloads.py
â””â”€â”€ README.md              # This file
```

### Running Tests

```bash
# Backend tests
cd backend
pytest tests/

# Frontend tests
cd frontend
pytest tests/
```

### Adding New Features

1. **Backend**: Add new endpoints in `app/api/routes/`
2. **Frontend**: Extend UI components in `floatchat_app.py`
3. **Data Processing**: Add new processors in `data_cleaning/src/`
4. **Database**: Update schema in `data_cleaning/sql/`

## ğŸ“ˆ Performance

- **âš¡ Query Response Time**: < 2 seconds average
- **ğŸ‘¥ Concurrent Users**: 50+ simultaneous queries
- **ğŸ’¾ Database Performance**: Optimized for ARGO data patterns
- **ğŸ” Vector Search**: Sub-second semantic similarity
- **ğŸ“Š Processing Speed**: ~100 NetCDF files/minute

## ğŸ”’ Security

- **ğŸ›¡ï¸ Input Validation**: Comprehensive validation on all endpoints
- **ğŸš« SQL Injection Prevention**: Parameterized queries
- **â±ï¸ Rate Limiting**: Configurable request limits

## ğŸ› Troubleshooting

### Common Issues

1. **Database Connection Failed**:
   ```bash
   # Check PostgreSQL service
   sudo systemctl restart postgresql
   ```

2. **Vector Database Empty**:
   ```bash
   cd data_cleaning
   python src/vector_db_manager.py
   ```

3. **Groq API Errors**:
   - Verify API key in `.env`
   - Check rate limits and quotas

4. **Memory Issues**:
   - Reduce batch size in processing
   - Restart application services

### Health Checks

```bash
# Overall system health
curl http://localhost:8000/health

# Database health
curl http://localhost:8000/health/database

# Vector database health
curl http://localhost:8000/health/vector-db
```

## ğŸ¤ Contributing

This project was built for the ARGO AI Hackathon and demonstrates:

- **ğŸŒŠ End-to-end RAG pipeline** for oceanographic data
- **ğŸ—£ï¸ Natural language interface** for complex scientific queries
- **ğŸ“ˆ Scalable architecture** for real-world deployment
- **ğŸ” Multi-modal data access** combining SQL and vector search

### Development Guidelines

1. **Code Style**: Follow PEP 8 and use type hints
2. **Testing**: Add tests for new features
3. **Documentation**: Update README files for changes
4. **Performance**: Monitor query response times
5. **Security**: Validate all inputs and sanitize outputs

## ğŸ“„ License

This project is built for educational and research purposes. See individual component licenses for details.

## ğŸ¯ Future Enhancements

- [ ] **ğŸ”„ Real-time Data Ingestion**: Live ARGO DAC integration
- [ ] **ğŸ“Š Advanced Visualizations**: 3D ocean models and animations
- [ ] **ğŸŒ Multi-language Support**: Internationalization
- [ ] **ğŸ¤– Custom Model Fine-tuning**: Domain-specific models
- [ ] **ğŸ›°ï¸ Satellite Data Integration**: Multi-source ocean data
- [ ] **ğŸ“¤ NetCDF Export**: Standard oceanographic formats
- [ ] **ğŸ—ºï¸ Advanced Geospatial Analysis**: Spatial statistics and modeling

## ğŸ“ Support

For questions or issues:

- **ğŸ“‹ Check the troubleshooting section** above
- **ğŸ“ Review log files** for detailed error information
- **ğŸ› Create an issue** in the repository
- **ğŸ’¬ Contact the development team**

## ğŸŒŠ Use Cases

- **ğŸ”¬ Oceanographic Research**: Climate studies, ocean circulation analysis
- **ğŸ“š Education**: Teaching oceanography and data science
- **ğŸ¤– Chatbot Integration**: Semantic search for oceanographic queries
- **ğŸ  Marine Biology**: Study of ocean ecosystems and habitats
- **ğŸŒ¡ï¸ Climate Monitoring**: Long-term ocean temperature and salinity trends
- **ğŸ“Š Data Science**: Machine learning on oceanographic datasets

---

**Built with â¤ï¸ for the SIH Hackathon **

*FloatChat makes the vast ocean of data accessible to everyone, from researchers to students, through the power of artificial intelligence and natural language processing.*
